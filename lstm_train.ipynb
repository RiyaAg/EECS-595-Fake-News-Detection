{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447dc8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79c91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3b010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dataset = load_dataset('liar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0801a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lstm_dataset['train']\n",
    "val = lstm_dataset['validation']\n",
    "test = lstm_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12d8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_model(model):\n",
    "    wv_from_bin = api.load(model)\n",
    "    return wv_from_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da48bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = \"glove-wiki-gigaword-200\"\n",
    "wv_from_bin = load_embedding_model(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d338e2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sentences = train['statement']\n",
    "train_labels = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae097fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, wv_from_bin):\n",
    "\n",
    "    # build vocab\n",
    "    corpus = []\n",
    "    vocab = {\"<PAD>\":0, \"UNKA\":1}\n",
    "    count_v = 2\n",
    "    X = []\n",
    "    vocab_count = {}\n",
    "    words = list(wv_from_bin.index_to_key)\n",
    "    \n",
    "    for l in data:\n",
    "        line = l.split()\n",
    "        sentence = []\n",
    "        for i in range(len(line)):\n",
    "            if line[i] not in words:\n",
    "                sentence.append(\"UNKA\")\n",
    "            else:\n",
    "                sentence.append(line[i])\n",
    "        corpus.append(sentence)\n",
    "\n",
    "    for l in range(len(corpus)):\n",
    "        line = corpus[l]\n",
    "        sent_x = []\n",
    "        tag_y = []\n",
    "        for i in range(len(line)):\n",
    "            if line[i] == \"UNKA\":\n",
    "                sent_x.append(line[i])\n",
    "            else:\n",
    "                sent_x.append(line[i].lower())\n",
    "                if line[i].lower() not in vocab:\n",
    "                    vocab[line[i].lower()] = count_v\n",
    "                    count_v += 1\n",
    "\n",
    "        X.append(sent_x)\n",
    "    \n",
    "    # map the sentence using the vocab word to index dictionary\n",
    "    X =  [[vocab[word] for word in sentence] for sentence in X]\n",
    "\n",
    "    return vocab, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4cb7d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_train, X = preprocess(train_sentences, wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9594d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_len = len(vocab_train)\n",
    "weights_matrix = np.zeros((matrix_len, 200), dtype = np.float32)\n",
    "\n",
    "for i, (key, value) in enumerate(vocab_train.items()):\n",
    "    try: \n",
    "        if key == \"<PAD>\" or key == \"UNKA\":\n",
    "            weights_matrix[i] = np.random.normal(scale=0.6, size=(200, ))\n",
    "        else:\n",
    "            weights_matrix[i] = wv_from_bin.get_vector(key)\n",
    "    except KeyError:\n",
    "        print('-------------ERROR------------')\n",
    "\n",
    "weights_vectors = torch.from_numpy(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b7e174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, weights_vectors, tagset_size):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(weights_vectors, padding_idx = 0)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        x = self.dropout(embeds)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        tag_scores = self.hidden2tag(ht[-1])\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d69a4b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNTagger(200, 45, weights_vectors, 6) \n",
    "loss_function = nn.CrossEntropyLoss(ignore_index = 0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8deb025",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs in range(10):\n",
    "    for sentence, y_true in zip(X, train_labels):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sentence = torch.tensor(sentence, dtype = torch.long)\n",
    "        y_true = torch.tensor(y_true, dtype = torch.long)\n",
    "\n",
    "        y_pred = model(sentence)\n",
    "\n",
    "        loss = loss_function(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71ddd8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "test_sentences = test['statement']\n",
    "test_labels = test['label']\n",
    "X_test = []\n",
    "\n",
    "for l in test_sentences:\n",
    "    line = l.split()\n",
    "    sentence = []\n",
    "    tag = []\n",
    "    for i in range(len(line)):\n",
    "        if line[i] == \"UNKA\":\n",
    "            sentence.append(line[i])\n",
    "        elif line[i].lower() not in vocab_train:\n",
    "            sentence.append(\"UNKA\")\n",
    "        else:\n",
    "            sentence.append(line[i].lower())\n",
    "    X_test.append(sentence)\n",
    "\n",
    "X_test =  [[vocab_train[word] for word in sentence] for sentence in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "235597b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sentence, yt_true in zip(X_test, test_labels):\n",
    "        \n",
    "        sentence = torch.tensor(sentence, dtype = torch.long)\n",
    "        yt_true = torch.tensor(yt_true, dtype = torch.long)\n",
    "\n",
    "        yt_pred = model(sentence)\n",
    "\n",
    "        pred = torch.argmax(yt_pred, -1).cpu().numpy()\n",
    "\n",
    "        prediction.append(pred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5c81ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is  23.46%\n",
      "The F1 score of the model is   0.23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "score = accuracy_score(prediction, test_labels)\n",
    "print(f\"The accuracy of the model is {100*score:6.2f}%\")\n",
    "f1score = f1_score(test_labels, prediction, average='micro')\n",
    "print(f\"The F1 score of the model is {f1score:6.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
